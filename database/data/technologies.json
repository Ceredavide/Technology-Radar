{"_id":{"$oid":"65df552f590aaf6b5471bad9"},"name":"Design Systems","description":"Design systems define a collection of design patterns, component libraries and good design and engineering practices that ensure consistent digital products.","category":"Techniques","ring":"Adopt","descriptionCategorization":"Evolved from the corporate style guides of the past, design systems offer shared libraries and documents that are easy to find and use. Generally, guidance is written down as code and kept under version control so that the guide is less ambiguous and easier to maintain than simple documents. Design systems have become a standard approach when working across teams and disciplines in product development because they allow teams to focus. They can address strategic challenges around the product itself without reinventing the wheel every time a new visual component is needed.","creator":{"$oid":"65df5396590aaf6b5471ba20"},"published":true,"publisher":{"$oid":"65df5396590aaf6b5471ba20"},"publishedAt":{"$date":"2024-02-28T16:09:00.579Z"},"edits":[{"user":{"$oid":"65df5396590aaf6b5471ba20"},"time":{"$date":"2024-02-28T16:01:29.312Z"},"action":"technology","_id":{"$oid":"65df58d9590aaf6b5471bbaf"}}],"createdAt":{"$date":"2024-02-28T15:45:51.426Z"},"updatedAt":{"$date":"2024-02-28T16:09:00.58Z"},"__v":0}
{"_id":{"$oid":"65df555e590aaf6b5471bae1"},"name":"Lightweight approach to RFCs","description":"A Request for Comments (RFC) is a formal document that includes context-dependent design and architectural ideas to facilitate team collaboration and decision-making.","category":"Techniques","ring":"Adopt","descriptionCategorization":"Nearly all digital native and scaleup organizations use RFCs to capture decisions around design, architecture, techniques and the ways their teams collaborate. Mature organizations have used RFCs in autonomous teams to drive better communication and collaboration, especially in cross-team decision-making. They're often used as a process to review and ratify architecture decision records. The result is a transparent collaborative process that allows those affected by a decision the chance to weigh in and provide input before the decision is ratified. So often in fast-moving environments, the reasoning leading up to design decisions gets lost along the way and teams who are responsible for implementing the decision are left scratching their heads.","creator":{"$oid":"65df5396590aaf6b5471ba20"},"published":true,"publisher":{"$oid":"65df5396590aaf6b5471ba20"},"publishedAt":{"$date":"2024-02-28T16:00:18.28Z"},"edits":[],"createdAt":{"$date":"2024-02-28T15:46:38.239Z"},"updatedAt":{"$date":"2024-02-28T16:00:18.28Z"},"__v":0}
{"_id":{"$oid":"65df559e590aaf6b5471bae9"},"name":"OIDC for GitHub Actions","description":"One of the techniques we recommend for implementing zero trust security for CI/CD is to authenticate your pipelines for cloud services access via federated identity mechanisms like OpenID Connect (OIDC).","category":"Techniques","ring":"Trial","descriptionCategorization":"As GitHub Actions is widely used — and this important technique remains underused — we want to call out OIDC for GitHub Actions. This way you can avoid storing long-lived access tokens for your cloud resources, and your pipelines won't get direct access to secrets. However, be sure to scope access carefully so that actions really run with least privilege.","creator":{"$oid":"65df5396590aaf6b5471ba20"},"published":true,"publisher":{"$oid":"65df5396590aaf6b5471ba20"},"publishedAt":{"$date":"2024-02-28T16:04:19.946Z"},"edits":[],"createdAt":{"$date":"2024-02-28T15:47:42.878Z"},"updatedAt":{"$date":"2024-02-28T16:04:19.947Z"},"__v":0}
{"_id":{"$oid":"65df55d0590aaf6b5471baf1"},"name":"GitOps","description":"GitOps is a technique for deploying applications via the control loop pattern.","category":"Techniques","ring":"Assess","descriptionCategorization":" An operator keeps the deployed application synchronized with configuration, usually a Git repository. When we last wrote about GitOps, the community had yet to agree on a definition of the term. At the time, we were concerned about common interpretations of the technique that included approaches like \"branch per environment\" for configuration, which may lead to snowflakes as code. Moreover, the messaging around GitOps as an alternative to continuous delivery was confusing. Since then, the four GitOps principles have clarified the scope and nature of the technique.","creator":{"$oid":"65df5396590aaf6b5471ba20"},"published":true,"publisher":{"$oid":"65df5396590aaf6b5471ba20"},"publishedAt":{"$date":"2024-02-28T16:01:06.666Z"},"edits":[],"createdAt":{"$date":"2024-02-28T15:48:32.047Z"},"updatedAt":{"$date":"2024-02-28T16:01:06.667Z"},"__v":0}
{"_id":{"$oid":"65df55ff590aaf6b5471baf9"},"name":"Self-hosted LLMs","description":"Large language models (LLMs) generally require significant GPU infrastructure to operate, but there has been a strong push to get them running on more modest hardware.","category":"Techniques","ring":"Assess","descriptionCategorization":"Quantization of a large model can reduce memory requirements, allowing a high-fidelity model to run on less expensive hardware or even a CPU. Efforts such as llama.cpp make it possible to run LLMs on hardware including Raspberry Pis, laptops and commodity servers.\n\nMany organizations are deploying self-hosted LLMs. This is often due to security or privacy concerns, or, sometimes, a need to run models on edge devices. Open-source examples include GPT-J, GPT-JT and Llama. This approach offers better control of the model in fine-tuning for a specific use case, improved security and privacy as well as offline access. Although we've helped some of our clients self-host open-source LLMs for code completion, we recommend you carefully assess the organizational capabilities and the cost of running such LLMs before making the decision to self-host.","creator":{"$oid":"65df5396590aaf6b5471ba20"},"published":true,"publisher":{"$oid":"65df5396590aaf6b5471ba20"},"publishedAt":{"$date":"2024-02-28T16:08:53.003Z"},"edits":[],"createdAt":{"$date":"2024-02-28T15:49:19.688Z"},"updatedAt":{"$date":"2024-02-28T16:08:53.004Z"},"__v":0}
{"_id":{"$oid":"65df5631590aaf6b5471bb01"},"name":"ReAct prompting","description":"ReAct prompting is a method for prompting LLMs intended to improve the accuracy of their responses over competing methods such as chain-of-thought (CoT).","category":"Techniques","ring":"Adopt","descriptionCategorization":"","creator":{"$oid":"65df5396590aaf6b5471ba20"},"published":false,"publisher":null,"publishedAt":null,"edits":[],"createdAt":{"$date":"2024-02-28T15:50:09.426Z"},"updatedAt":{"$date":"2024-02-28T15:50:09.426Z"},"__v":0}
{"_id":{"$oid":"65df5660590aaf6b5471bb09"},"name":"Ignoring OWASP Top 10 lists","description":"The OWASP Top 10 has long been a go-to reference for the most critical security risks to web applications. Despite being well-known, we've previously written about it being underused in the software development process and cautioned against ignoring OWASP Top 10.","category":"Techniques","ring":"","descriptionCategorization":"What is less well-known is that OWASP also publishes similar top 10 lists for other categories. The OWASP Top 10 list for LLMs, whose first major version was released early August, highlights risks such as prompt injection, insecure output handling, training data poisoning and others that individuals and teams building LLM applications would do well to be aware of. OWASP has also recently released the second version of its OWASP Top 10 list for APIs. Given the OWASP Top 10 lists' breadth of coverage (web applications, APIs, LLMs and more), quality and relevance to the continuously changing security landscape, we extend our previous recommendation to caution teams against ignoring OWASP Top 10 lists.","creator":{"$oid":"65df5396590aaf6b5471ba20"},"published":false,"publisher":null,"publishedAt":null,"edits":[],"createdAt":{"$date":"2024-02-28T15:50:56.115Z"},"updatedAt":{"$date":"2024-02-28T15:50:56.115Z"},"__v":0}
{"_id":{"$oid":"65df56b9590aaf6b5471bb11"},"name":"dbt","description":"dbt continues to be our tool of choice for data transformations in the ELT workflow.","category":"Tools","ring":"Adopt","descriptionCategorization":"We like that it lends itself to engineering rigor and enables practices like modularity, testability and reusability of SQL-based transformations. dbt is available both as an open-source and commercial SaaS product and has a healthy ecosystem, including a community hub with packages for unit testing, data quality and data observability, to name a few. Packages worth highlighting include dbt-expectations and dbt-unit-testing which facilitate data quality checks and unit testing of the transformations, respectively. dbt integrates well with a variety of cloud data warehouses, lakehouses and databases, including Snowflake, BigQuery, Redshift, Databricks and Postgres. When working with structured data where one can set up transformations as SQL, our teams prefer dbt — which is why we're moving it to Adopt.","creator":{"$oid":"65df5396590aaf6b5471ba20"},"published":false,"publisher":null,"publishedAt":null,"edits":[],"createdAt":{"$date":"2024-02-28T15:52:25.954Z"},"updatedAt":{"$date":"2024-02-28T15:52:25.954Z"},"__v":0}
{"_id":{"$oid":"65df56d6590aaf6b5471bb19"},"name":"Ruff","description":"Ruff is a relatively new linter for Python. When it comes to linters, for us the question is not whether to use a linter but which linter to use.","category":"Tools","ring":"Trial","descriptionCategorization":"Ruff stands out for its out-of-box experience and its speed. It has more than 500 built-in rules and readily replaces Flake8, including many of that linter's plugins. The Ruff team’s claims about its performance are borne out by our experience; it really is at least an order of magnitude faster than other linters which is a huge benefit, because it helps reduce build times on large codebases. For these reasons, Ruff has become our default choice as a Python linter.","creator":{"$oid":"65df5396590aaf6b5471ba20"},"published":true,"publisher":{"$oid":"65df5396590aaf6b5471ba20"},"publishedAt":{"$date":"2024-02-28T16:01:21.164Z"},"edits":[],"createdAt":{"$date":"2024-02-28T15:52:54.864Z"},"updatedAt":{"$date":"2024-02-28T16:01:21.165Z"},"__v":0}
{"_id":{"$oid":"65df5738590aaf6b5471bb21"},"name":"WS Control Tower","description":"Multi-team account management is a challenge in AWS, especially in setup and governance.","category":"Tools","ring":"Trial","descriptionCategorization":" AWS Control Tower addresses this challenge by simplifying setup and automating governance; it addresses regulatory requirements with guardrails. AWS Control Tower has a built-in Account Factory that helps automate the account provisioning workflow. Among other things, you can update, unmanage and close accounts that you create and provision through Account Factory. Due to its lack of automation and customization, Amazon introduced AWS Control Tower Account Factory for Terraform (AFT). AFT allows you to provision customizations to send webhooks or take specific actions that allow for the integration with other tools to kick off jobs as part of the account creation process. One of the use cases leveraged by our team was to manage a set of out-of-the box items for accounts that were set-and-forget configurations for baselining and creating access for roles for GitHub Actions.","creator":{"$oid":"65df5396590aaf6b5471ba20"},"published":false,"publisher":null,"publishedAt":null,"edits":[],"createdAt":{"$date":"2024-02-28T15:54:32.36Z"},"updatedAt":{"$date":"2024-02-28T15:54:32.36Z"},"__v":0}
{"_id":{"$oid":"65df5762590aaf6b5471bb29"},"name":"Bloc","description":"Bloc is a reactive state management library for Flutter.","category":"Tools","ring":"","descriptionCategorization":"Among the available state management options for Flutter, we want to highlight Bloc because our teams have had good experience with the library when building complex mobile applications. Structurally organizing code around the BLoC pattern resulted in clean separation of business logic from the presentation layer as the UI Widgets communicate via streams and event sinks with business logic. Bloc also has good plugin support in both IntelliJ and VSCode IDEs.","creator":{"$oid":"65df5396590aaf6b5471ba20"},"published":false,"publisher":null,"publishedAt":null,"edits":[],"createdAt":{"$date":"2024-02-28T15:55:14.345Z"},"updatedAt":{"$date":"2024-02-28T15:55:14.345Z"},"__v":0}
{"_id":{"$oid":"65df578a590aaf6b5471bb31"},"name":"ChatGPT","description":"ChatGPT continues to attract attention.","category":"Tools","ring":"Assess","descriptionCategorization":"GPT4, the large language model (LLM) that powers ChatGPT, now also has the ability to integrate with external tools such as a knowledge management repository, sandboxed coding environment or web search. The recent introduction of ChatGPT Enterprise may help ease intellectual property concerns, while providing \"enterprise\" features such as usage tracking and better user management through SSO.\n\nAlthough ChatGPT's ability to \"write\" code has been much vaunted, we think organizations should be looking at using it across the full software lifecycle to improve efficiency and reduce errors. For example, ChatGPT can provide additional perspectives or suggestions for tasks as diverse as requirements analysis, architectural design or the reverse engineering of legacy systems. ","creator":{"$oid":"65df5396590aaf6b5471ba20"},"published":true,"publisher":{"$oid":"65df5396590aaf6b5471ba20"},"publishedAt":{"$date":"2024-02-28T16:01:15.357Z"},"edits":[],"createdAt":{"$date":"2024-02-28T15:55:54.604Z"},"updatedAt":{"$date":"2024-02-28T16:01:15.357Z"},"__v":0}
{"_id":{"$oid":"65df57b0590aaf6b5471bb39"},"name":"Colima","description":"Colima is now our go-to alternative to Docker Desktop on macOS. ","category":"Platforms","ring":"Adopt","descriptionCategorization":"We continue to use it on several projects to provision the Docker container run time in a Lima VM, to configure the Docker CLI on macOS and to handle port-forwarding and volume mounts. Colima can be configured to run containerd as its run time, which is also the run time on most managed Kubernetes services, improving the important dev-prod parity.","creator":{"$oid":"65df5396590aaf6b5471ba20"},"published":true,"publisher":{"$oid":"65df5396590aaf6b5471ba20"},"publishedAt":{"$date":"2024-02-28T15:56:54Z"},"edits":[],"createdAt":{"$date":"2024-02-28T15:56:32.188Z"},"updatedAt":{"$date":"2024-02-28T15:56:54.001Z"},"__v":0}
{"_id":{"$oid":"65df57f9590aaf6b5471bb4f"},"name":"Orca","description":"Orca is a proprietary cloud security platform that identifies, prioritizes and remediates security risks and compliance issues.","category":"Platforms","ring":"Assess","descriptionCategorization":". It supports major cloud providers and hybrid setups. Orca has extensive security queries/rules to continuously monitor deployed workloads for misconfigurations, vulnerabilities and compliance issues. It supports cloud VMs, serverless functions, containers and Kubernetes applications for the deployed workloads. These inbuilt security rules are consistently updated to keep pace with the evolving compliance standards and threat vectors. Since Orca is agentless, it offers a good developer experience and is easy to set up. Another notable feature is that it facilitates shift left security. Our teams use Orca CLI for scanning container images and IaC templates for vulnerabilities and misconfigurations as a pre-commit hook or as part of CI/CD workflows.","creator":{"$oid":"65df5396590aaf6b5471ba20"},"published":false,"publisher":null,"publishedAt":null,"edits":[],"createdAt":{"$date":"2024-02-28T15:57:45.936Z"},"updatedAt":{"$date":"2024-02-28T15:57:45.936Z"},"__v":0}
{"_id":{"$oid":"65df5818590aaf6b5471bb58"},"name":"Trino","description":"Trino, previously known as PrestoSQL, is an open-source, distributed SQL query engine designed for interactive analytic queries over big data. ","category":"Platforms","ring":"Trial","descriptionCategorization":" It is optimized to run both on-premise and in the cloud. It supports querying data where it lives, including Hive, Cassandra, relational databases and even proprietary data stores. For authentication mechanisms, it supports password-based authentication, LDAP and OAuth. For authorization and access control, Trino provides the ability to grant access at the catalog, schema and table levels. Our teams used resource groups spliced according to consumption patterns like visualization, reporting or machine learning use cases to manage and limit resource usage. The JMX-based monitoring provides a rich set of metrics to enable cost attribution at query or user level. Our teams use Trino as a gateway for data access across a variety of sources. When it comes to querying extremely large-scale data, Trino is a safe bet for our teams. Presto, the Facebook project from which Trino originates, was first featured in the Radar in November 2015.","creator":{"$oid":"65df5396590aaf6b5471ba20"},"published":true,"publisher":{"$oid":"65df5396590aaf6b5471ba20"},"publishedAt":{"$date":"2024-02-28T16:09:18.825Z"},"edits":[],"createdAt":{"$date":"2024-02-28T15:58:16.224Z"},"updatedAt":{"$date":"2024-02-28T16:09:18.827Z"},"__v":0}
{"_id":{"$oid":"65df583b590aaf6b5471bb61"},"name":"Wiz","description":"Wiz is another contender in the maturing cloud security platform landscape that allows its users to prevent, detect and respond to security risks and threats in one platform. ","category":"Platforms","ring":"Hold","descriptionCategorization":" Wiz can detect and alert on misconfigurations, vulnerabilities and leaked secrets both in artifacts that have yet to be deployed to live environments (container images, infrastructure code) as well as live workloads (containers, VMs and cloud services). It also contextualizes findings to the customer's specific cloud landscape to enable response teams to better understand the issue and prioritize mitigations. Our teams have had good experience with Wiz. They find that Wiz is rapidly evolving and adding new features, and they appreciate that it enables them to detect risks and threats sooner than some other similar tools as it continuously scans for changes.","creator":{"$oid":"65df5396590aaf6b5471ba20"},"published":false,"publisher":null,"publishedAt":null,"edits":[],"createdAt":{"$date":"2024-02-28T15:58:51.937Z"},"updatedAt":{"$date":"2024-02-28T15:58:51.937Z"},"__v":0}
{"_id":{"$oid":"65df586a590aaf6b5471bb6a"},"name":"ActivityPub","description":"With the current upheaval in the micro-blogging platform space, the ActivityPub protocol is gaining prominence.","category":"Platforms","ring":"Adopt","descriptionCategorization":"ActivityPub is an open protocol for sharing information such as posts, publications and dates. It can be used to implement a social media platform, but the key benefit is that it delivers interoperability between different social media platforms. We expect ActivityPub will play a significant role in this space, but we're mentioning it here because we're intrigued by the possibilities beyond the obvious use cases in social media. An example is ActivityPub support for merge requests, recently proposed for GitLab.","creator":{"$oid":"65df5396590aaf6b5471ba20"},"published":false,"publisher":null,"publishedAt":null,"edits":[{"user":{"$oid":"65df5396590aaf6b5471ba20"},"time":{"$date":"2024-02-28T16:03:03.574Z"},"action":"technology","_id":{"$oid":"65df5937590aaf6b5471bbdf"}}],"createdAt":{"$date":"2024-02-28T15:59:38.016Z"},"updatedAt":{"$date":"2024-02-28T16:03:03.576Z"},"__v":0}
{"_id":{"$oid":"65df588a590aaf6b5471bb73"},"name":"ChatGLM","description":" ChatGLM, developed by Tsinghua University, is an open bilingual language model optimized for Chinese conversation based on the General Language Model architecture.","category":"Platforms","ring":"","descriptionCategorization":"Since Chinese can be more complex than English with its different word segmentation and grammar, it’s important to have an LLM optimized for Chinese. Our team found ChatGLM beat other LLMs in accuracy and robustness when we built a Chinese emotion detection application for a call center. Considering many LLMs aren’t available in China due to licensing or regional restrictions, ChatGLM became one of the few open-source options.","creator":{"$oid":"65df5396590aaf6b5471ba20"},"published":false,"publisher":null,"publishedAt":null,"edits":[],"createdAt":{"$date":"2024-02-28T16:00:10.434Z"},"updatedAt":{"$date":"2024-02-28T16:00:10.434Z"},"__v":0}
{"_id":{"$oid":"65df58b8590aaf6b5471bb86"},"name":"Playwright","description":"With Playwright you can write end-to-end tests that run in Chrome, Firefox and WebKit. By using the Chrome DevTools Protocol (CDP) Playwright can offer new features and eliminate many of the issues seen with WebDriver.","category":"Tools","ring":"Adopt","descriptionCategorization":" Chromium-based browsers implement CDP directly. To support Firefox and Webkit, though, the Playwright team has to submit patches to these browsers, which may sometimes limit the framework.\nPlaywright’s many features include: Built-in auto-waits, which result in tests that are more reliable and easier to understand; browser contexts, which let you test that persisting sessions across tabs work properly; and the ability to simulate notifications, geolocation and dark mode settings. Our teams are impressed with the stability Playwright brings to the test suite and like that they get feedback more quickly by running tests in parallel. Other features that set Playwright apart include better support for lazy loading and tracing. ","creator":{"$oid":"65df5396590aaf6b5471ba20"},"published":true,"publisher":{"$oid":"65df5396590aaf6b5471ba20"},"publishedAt":{"$date":"2024-02-28T16:04:06.478Z"},"edits":[{"user":{"$oid":"65df5396590aaf6b5471ba20"},"time":{"$date":"2024-02-28T16:02:04.255Z"},"action":"technology","_id":{"$oid":"65df58fc590aaf6b5471bbc8"}}],"createdAt":{"$date":"2024-02-28T16:00:56.341Z"},"updatedAt":{"$date":"2024-02-28T16:04:06.479Z"},"__v":0}
{"_id":{"$oid":"65df5953590aaf6b5471bbeb"},"name":"Polars","description":"Polars is an in-memory data frame library implemented in Rust. ","category":"Platforms","ring":"Hold","descriptionCategorization":"Unlike other data frames (such as pandas), Polars is multithreaded, supports lazy execution and is safe for parallel operations. The in-memory data is organized in the Apache Arrow format for efficient analytic operations and to enable interoperability with other tools. If you're familiar with pandas, you can quickly get started with Polars' Python bindings. We believe Polars, with Rust implementation and Python bindings, is a performant in-memory data frame for your analytical needs. Our teams continue to have a good experience with Polars which is why we're moving it to Trial.","creator":{"$oid":"65df5396590aaf6b5471ba20"},"published":true,"publisher":{"$oid":"65df5396590aaf6b5471ba20"},"publishedAt":{"$date":"2024-02-28T16:03:37.375Z"},"edits":[{"user":{"$oid":"65df5396590aaf6b5471ba20"},"time":{"$date":"2024-02-28T16:03:46.239Z"},"action":"technology","_id":{"$oid":"65df5962590aaf6b5471bc08"}}],"createdAt":{"$date":"2024-02-28T16:03:31.203Z"},"updatedAt":{"$date":"2024-02-28T16:03:46.24Z"},"__v":0}
{"_id":{"$oid":"65df59d6599c75c6e604b21e"},"name":"Polars","description":"Polars is an in-memory data frame library implemented in Rust. Unlike other data frames (such as pandas), Polars is multithreaded, supports lazy execution and is safe for parallel operations.  We believe Polars, with Rust implementation and Python bindings, is a performant in-memory data frame for your analytical needs. Our teams continue to have a good experience with Polars which is why we're moving it to Trial.","category":"Languages_Frameworks","ring":"Trial","descriptionCategorization":"The in-memory data is organized in the Apache Arrow format for efficient analytic operations and to enable interoperability with other tools. If you're familiar with pandas, you can quickly get started with Polars' Python bindings. ","creator":{"$oid":"65df5396590aaf6b5471ba20"},"published":true,"publisher":{"$oid":"65df5396590aaf6b5471ba20"},"publishedAt":{"$date":"2024-02-28T16:06:22.098Z"},"edits":[{"user":{"$oid":"65df5396590aaf6b5471ba20"},"time":{"$date":"2024-02-28T16:05:57.598Z"},"action":"technology","_id":{"$oid":"65df59e5599c75c6e604b230"}}],"createdAt":{"$date":"2024-02-28T16:05:42.028Z"},"updatedAt":{"$date":"2024-02-28T16:06:22.101Z"},"__v":0}
{"_id":{"$oid":"65df5a1f599c75c6e604b258"},"name":"Baseline Profiles","description":"Baseline Profiles — not to be confused with Android Baseline profiles — are Android Runtime profiles that guide ahead-of-time compilation.","category":"Languages_Frameworks","ring":"Trial","descriptionCategorization":"","creator":{"$oid":"65df5396590aaf6b5471ba20"},"published":false,"publisher":null,"publishedAt":null,"edits":[],"createdAt":{"$date":"2024-02-28T16:06:55.059Z"},"updatedAt":{"$date":"2024-02-28T16:06:55.059Z"},"__v":0}
{"_id":{"$oid":"65df5a3a599c75c6e604b267"},"name":"GGML","description":"GGML is a C library for machine learning that allows for CPU inferencing.","category":"Languages_Frameworks","ring":"Adopt","descriptionCategorization":" It defines a binary format for distributing large language models (LLMs). To do that it uses quantization, a technique that allows LLMs to run on consumer hardware with effective CPU inferencing. GGML supports a number of different quantization strategies (e.g., 4-bit, 5-bit, and 8-bit quantization), each of which offers different trade-offs between efficiency and performance. A quick way to test, run and build apps with these quantized models is a Python binding called C Transformers. This is a Python wrapper on top of GGML that takes away the boilerplate code for inferencing by providing a high level API. We've leveraged these libraries to build proof of concepts and experiments.","creator":{"$oid":"65df5396590aaf6b5471ba20"},"published":true,"publisher":{"$oid":"65df5396590aaf6b5471ba20"},"publishedAt":{"$date":"2024-02-28T16:09:30.116Z"},"edits":[],"createdAt":{"$date":"2024-02-28T16:07:22.926Z"},"updatedAt":{"$date":"2024-02-28T16:09:30.117Z"},"__v":0}
{"_id":{"$oid":"65df5a56599c75c6e604b276"},"name":"htmx","description":"htmx is a small, neat HTML UI library that recently became popular seemingly out of nowhere. ","category":"Languages_Frameworks","ring":"Assess","descriptionCategorization":"During our Radar discussion, we found its predecessor intercooler.js existed ten years ago. Unlike other increasingly complex pre-compiled JavaScript/TypeScript frameworks, htmx encourages the direct use of HTML attributes to access operations such as AJAX, CSS transitions, WebSockets and Server-Sent Events. There's nothing technically sophisticated about htmx, but its popularity recalls the simplicity of hypertext in the early days of the web. The project’s website also features some insightful (and amusing) essays on hypermedia and web development, which suggests the team behind htmx have thought carefully about its purpose and philosophy.","creator":{"$oid":"65df5396590aaf6b5471ba20"},"published":false,"publisher":null,"publishedAt":null,"edits":[],"createdAt":{"$date":"2024-02-28T16:07:50.95Z"},"updatedAt":{"$date":"2024-02-28T16:07:50.95Z"},"__v":0}
{"_id":{"$oid":"65df5a85599c75c6e604b287"},"name":"GPTCache","description":"GPTCache is a semantic cache library for large language models (LLMs). We see the need for a cache layer in front of LLMs for two main reasons — to improve the overall performance by reducing external API calls and to reduce the cost of operation by caching similar responses. ","category":"Languages_Frameworks","ring":"","descriptionCategorization":". Unlike traditional caching approaches that look for exact matches, LLM-based caching solutions require similar or related matches for the input queries. GPTCache approaches this with the help of embedding algorithms to convert the input queries into embeddings and then use a vector datastore for similarity search on these embeddings. One drawback of such a design is that you may encounter false positives during cache hits or false negatives during cache misses, which is why we recommend you carefully assess GPTCache for your LLM-based applications.","creator":{"$oid":"65df5396590aaf6b5471ba20"},"published":false,"publisher":null,"publishedAt":null,"edits":[],"createdAt":{"$date":"2024-02-28T16:08:37.57Z"},"updatedAt":{"$date":"2024-02-28T16:08:37.57Z"},"__v":0}
